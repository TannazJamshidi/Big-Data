{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fa33070-acdf-4208-b45d-abe3dee033e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath1 = \"/data/students/bigdata_internet/lab3/register.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6fcbc5d-0879-4fd9-95b7-39d5895895e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputPath2 = \"/data/students/bigdata_internet/lab3/stations.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "083b12cb-60f3-4e54-9982-7ff505e4fde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_register = spark.read.load(inputPath1,sep =\"\\t\",format = \"csv\",header =True , inferscherma=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29bfc1e8-50e3-4003-9c94-5ba9dd6c82ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of total before editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53346909-b177-4144-85c7-4b7f6c991dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25319028"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_register.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cf48816-a080-468e-a13c-a124a8e8e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_register.createOrReplaceTempView(\"st\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bae97b2d-6957-4cf5-8007-001766200fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_reg = spark.sql(\"SELECT * FROM st WHERE NOT (used_slots = 0 AND free_slots = 0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b295bd25-2a66-4c7b-b6a1-f666be7d46d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25104121"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_reg.count() # number of rows after data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3ebf44b-461b-4939-9988-ddbbc511c221",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station = spark.read.load(inputPath2,sep = \"\\t\" ,format = \"csv\",header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc2c759f-df74-4776-90cb-7c50c027c251",
   "metadata": {},
   "outputs": [],
   "source": [
    "withTimeSlot = filtered_reg.selectExpr(\"station\",\"(date_format(timestamp,'EEEE'),hour(timestamp)) AS Tj \",\n",
    "                     \"used_slots\",\"free_slots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cdbc2df-63d0-42fa-ac00-17d5597fd0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "withTimeSlot.createOrReplaceTempView(\"sttm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de0d300a-52a8-4f61-a93c-e930c243a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "allReadings = spark.sql(\"SELECT station,Tj,count(station) AS countAll FROM sttm GROUP BY station,Tj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adfbcef9-a42d-4cf3-ad79-ebfe6f789fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "allReadings.createOrReplaceTempView(\"AllReadings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70e502b8-0020-48a0-8dc8-14a23a6857f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criticalsReadings = spark.sql(\" SELECT station,Tj,COUNT(station) AS countCriticals FROM sttm WHERE free_slots = 0 GROUP BY station, Tj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d8bbe9b-27fc-48f9-b73d-d72e13fc9666",
   "metadata": {},
   "outputs": [],
   "source": [
    "criticalsReadings.createOrReplaceTempView(\"CriticalReadings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55970857-6607-48e8-b5f9-a8102ab5213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "joinedTable = spark.sql(\"\"\"\n",
    "    SELECT c.station, c.Tj, c.countCriticals, A.countAll\n",
    "    FROM CriticalReadings c ,AllReadings A\n",
    "    WHERE c.station = A.station\n",
    "    AND c.Tj = A.Tj\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ea32043-687d-4a72-9124-8fd4340b9a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "joinedTable.createOrReplaceTempView(\"joinedTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2731f5fc-5c77-4a0e-9c6b-004856e49bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SiTj = spark.sql(\"\"\"\n",
    "    SELECT station, Tj, countCriticals / countAll AS Csitj \n",
    "    FROM joinedtable \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb57209a-a94f-4fe8-9f27-c6292a3bfee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:====================================================>    (11 + 1) / 12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+--------------------+\n",
      "|station|            Tj|               Csitj|\n",
      "+-------+--------------+--------------------+\n",
      "|     10|[Wednesday, 2]| 0.15463917525773196|\n",
      "|    100|[Saturday, 14]| 0.01763668430335097|\n",
      "|    102|  [Tuesday, 7]|  0.0106951871657754|\n",
      "|    109|   [Sunday, 2]|0.013888888888888888|\n",
      "|     11|  [Monday, 10]| 0.20934579439252338|\n",
      "+-------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "SiTj.show(5) #2.1 for each pair(station,Tj) the criticality value is calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d391ee3-12b2-468c-86de-c8fec99bb1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "aboveThreshold = SiTj.filter('Csitj > 0.6') ##2.2 only critical pairs with above minimum criticality threshold(0.6) are selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37f60272-86d7-4583-b5eb-fa3f8e0b4e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aboveThreshold.createOrReplaceTempView(\"above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ddee4e0-e534-4a87-8475-ebfe929a4b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I change the day of weeks into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "50161306-c726-4b39-bb88-831e4c01001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "daysWithNumber = spark.sql('''SELECT \n",
    "    station,\n",
    "    CASE \n",
    "        WHEN Tj.col1 = \"Friday\" THEN struct(5 AS col1, Tj.col2)\n",
    "        WHEN Tj.col1 = \"Monday\" THEN struct(1 AS col1, Tj.col2)\n",
    "        WHEN Tj.col1 = \"Saturday\" THEN struct(6 AS col1, Tj.col2)\n",
    "    END AS Tj,\n",
    "    Csitj\n",
    "FROM \n",
    "    above''')\n",
    "daysWithNumber.createOrReplaceTempView(\"ordered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94bca88f-46da-4dce-a36c-87725556a690",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3 now orderin them by criticality value,station id,day of week and hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "53945ccd-6d8b-4dda-9329-508642cc75c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered = spark.sql('SELECT * FROM ordered ORDER BY Csitj,station,Tj.col1 ,Tj.col2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5100e156-85a4-4152-8cad-23139153d816",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered.createOrReplaceTempView(\"orderedday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dabecafb-f086-45c3-a33c-2daf00881e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,when\n",
    "\n",
    "daysWithWord = spark.sql('''SELECT \n",
    "    station,\n",
    "    CASE \n",
    "        WHEN Tj.col1 = 5 THEN struct(\"Friday\" AS col1, Tj.col2)\n",
    "        WHEN Tj.col1 = 1 THEN struct(\"Monday\" AS col1, Tj.col2)\n",
    "        WHEN Tj.col1 = 6 THEN struct(\"Saturday\" AS col1, Tj.col2)\n",
    "    END AS Tj,\n",
    "    Csitj\n",
    "FROM \n",
    "    orderedday''')\n",
    "# now days'number to day of week again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c6da19a2-a602-44ee-91ac-3b041461cbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station.createOrReplaceTempView(\"Stations_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "af2b4898-9656-43b1-83a0-c8f7dae423bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "daysWithWord.createOrReplaceTempView(\"ordering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bc054554-831b-4ff2-9e80-b6dfd81033f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "address = spark.sql(\"\"\"\n",
    "    SELECT S.id, S.longitude, S.latitude, S.name, O.Tj ,O.Csitj\n",
    "    FROM Stations_info S\n",
    "    JOIN ordering O ON S.id = O.station\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "12c840e3-ca85-4e0e-90c7-7cdd3207b72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = address.selectExpr('id AS `station id`',\n",
    "                       'name AS `station name`',\n",
    "                       'longitude AS `station longitude`',\n",
    "                       'latitude AS `station latitude`',\n",
    "                       'Tj.col1 AS `day of week`',\n",
    "                       'Tj.col2 AS `hour`',\n",
    "                       'Csitj AS `critality value`')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6d7d861b-8fe5-4b1c-bb1c-1f7923dddf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------------------+-----------------+----------------+-----------+----+------------------+\n",
      "|station id|station name                  |station longitude|station latitude|day of week|hour|critality value   |\n",
      "+----------+------------------------------+-----------------+----------------+-----------+----+------------------+\n",
      "|9         |MarquÃ¨s de l\\'Argentera      |2.185294         |41.385006       |Friday     |10  |0.6129032258064516|\n",
      "|10        |Avinguda del Marques Argentera|2.185206         |41.384875       |Saturday   |0   |0.622107969151671 |\n",
      "|58        |Sant Oleguer                  |2.170736         |41.377536       |Monday     |1   |0.6239554317548747|\n",
      "|9         |MarquÃ¨s de l\\'Argentera      |2.185294         |41.385006       |Friday     |22  |0.6258389261744967|\n",
      "|58        |Sant Oleguer                  |2.170736         |41.377536       |Monday     |0   |0.6323119777158774|\n",
      "+----------+------------------------------+-----------------+----------------+-----------+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "07a638d9-7f14-436c-b0cd-4ac5ca302a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputFile = \"/user/s310279/lab3/outPutBySQL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3c0a0997-8f0a-4316-9b93-574e161217cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.4 storing them with header and columns are separated by tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c680cb4c-b748-4ed7-9a4b-9cbb84e4329e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "w.write.option(\"delimiter\", \"\\t\").csv(outputFile, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421a5c76-2004-496b-9c0a-a9b15fe713b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Yarn)",
   "language": "python",
   "name": "pyspark_yarn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
