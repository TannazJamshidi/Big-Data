{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "167ea055-2d78-4677-ba45-a585d1fa8f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f44f460f-efe2-4460-978c-7012e5917c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = '/data/students/bigdata_internet/lab4/log_tcp_complete_classes.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "454072ae-c467-4692-aaa1-d9628f95f46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "inputDf = spark.read.load(inputFile,sep = ' ',format = \"csv\",header =True , inferSchema =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a2cb1dd-da5f-4af8-b765-e2803f3b519c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.1 number of columns/features the file has.\n",
    "columnsNumber = inputDf.columns\n",
    "len(columnsNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd84d32f-87e7-4089-88b7-c775bd70a7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/17 11:24:05 WARN util.Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.2 number of tcp conection\n",
    "rowsNumber = inputDf.count()\n",
    "rowsNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d82add3-c653-40b7-af8b-c47f1ca856e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Allclass = inputDf.groupBy(\"class:207\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b72d2cea-9efe-456b-800c-750644259070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.0.1 number of classes in the file\n",
    "Allclass.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b416e569-7416-4f33-9f6a-3b02cf7a99f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|      class:207|count|\n",
      "+---------------+-----+\n",
      "|   class:google|10000|\n",
      "|   class:amazon|10000|\n",
      "|class:instagram|10000|\n",
      "| class:facebook|10000|\n",
      "|  class:netflix|10000|\n",
      "|     class:ebay|10000|\n",
      "|  class:spotify|10000|\n",
      "| class:linkedin|10000|\n",
      "|  class:youtube|10000|\n",
      "|     class:bing|10000|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2.0.2 showing all the classes\n",
    "Allclass.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfe843ea-dec7-4492-9f0a-8f1655fef387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.0.3 it has 10 different classes in total,and each of them has 10000 connection per webservice presented in data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14d109a8-2dab-4493-ad7c-2692df582d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I choese these columns as selected features for training\n",
    "#c_bytes_uniq:7 (number of bytes sent in the payload from the client), \n",
    "#s_bytes_uniq:21 (number of bytes sent in the payload from the server)\n",
    "#c_pkts_data:8 (number of segments with payload from client)\n",
    "#s_pkts_data:22 (number of segments with payloadfrom server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b57f3fc5-f94e-4d3f-b192-5afe6cd907a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db69edb5-4860-45c0-b634-3010952e272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"class:207\", outputCol=\"ClassIndex\", handleInvalid=\"keep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f301fdf2-ed5b-4ca7-9e70-1e185978622a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "indexerModel= indexer.fit(inputDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40d972a7-9a29-4bd8-af82-4651add98d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexDF = indexerModel.transform(inputDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e10b7b-dee3-45db-bb62-47a568d3a9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1.1. Does it make sense to use the IP addresses + ports (`#31#c_ip:1`, `c_port:2`,`s_ip:15`, `s_port:16`) as features?\n",
    "#no we can not use them, ports and ip addresses are numerical and categorial which is not meaningful because machine learning measures \n",
    "#the distances which in this case doesn't make sense to  use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70c2cb8-2345-4e01-9e50-0e24487760bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1.2. Would it be fair to use the Fully Qualified Domain Name (FQDN, `fqdn:127`, forinstance `www.google.com`) for the classification?\n",
    "\n",
    "#using FQDNs as features for classification can be fair and effective, especially if they capture relevant information \n",
    "#about the classes of interest. we should ensure that we handle them appropriately, encoding, and the \n",
    "#dynamic nature of network traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b83022fd-c87a-42b4-afff-49591e4237a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresColumn = ['c_bytes_uniq:7', 's_bytes_uniq:21', 'c_pkts_data:8','s_pkts_data:22' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8d6a5fc-6cb6-4e32-afd5-fc04424ccdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols = featuresColumn, outputCol = 'features')\n",
    "transformedDF = vectorAssembler.transform(indexDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7291cbdb-770f-4ea0-8462-56d7e477e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read & Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a917c5d6-99c6-49d4-8ccd-1a8498eb5e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainValidation, test= transformedDF.randomSplit([0.75, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89d9ba6f-812b-4215-8973-44af468dda41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837390e7-fc5f-4be8-8377-26c75ff6fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.4.1 How much does it take to train the model (time in seconds), for the differentalgorithm and parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e58946a2-c57a-4029-a2f8-361404af24b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 26.020915031433105 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "dt = DecisionTreeClassifier(labelCol=\"ClassIndex\", featuresCol='features',maxDepth = 10)\n",
    "\n",
    "# Your training code\n",
    "dtModel = dt.fit(trainValidation)\n",
    "finalDF=dtModel.transform(trainValidation)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training time: {training_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5f0d582-b18b-453c-98ab-99ec6f01f551",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalTestDF=dtModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e703347-3b01-486e-b671-a2376d1546eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:======================================>                   (2 + 1) / 3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training Decision Tree is  0.5572778525636753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "myEvaluatorTree = MulticlassClassificationEvaluator(labelCol=\"ClassIndex\",predictionCol=\"prediction\",metricName='accuracy')\n",
    "print(\"Accuracy on training Decision Tree is \", myEvaluatorTree.evaluate(finalDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "500ba641-0fe4-49c1-8c7f-c9976b98a5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 49:======================================>                   (2 + 1) / 3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test Decision Tree is  0.5452324696648112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on test Decision Tree is \", myEvaluatorTree.evaluate(finalTestDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1260597-6528-4112-815b-398ed04f38f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6255fb8a-a04f-41b9-9ccd-c23fca0d0332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 75:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 29.339547872543335 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "start_time2 = time.time()\n",
    "rf = RandomForestClassifier(labelCol=\"ClassIndex\",featuresCol=\"features\",numTrees=20,maxDepth = 10)\n",
    "rfModel=rf.fit(trainValidation)\n",
    "finalDFForest=rfModel.transform(trainValidation)\n",
    "end_time2 = time.time()\n",
    "\n",
    "training_time2 = end_time2 - start_time2\n",
    "print(f\"Training time: {training_time2} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3746cea-a6fb-435b-a5e9-6de54ecb546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalTestDFForest=rfModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5131b17f-a7c1-4d77-8d38-198a4c088764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training Random Forest is  0.6380866065121487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 82:======================================>                   (2 + 1) / 3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test Random Forest is  0.6268070962316287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "myEvaluatorTree = MulticlassClassificationEvaluator(labelCol=\"ClassIndex\",predictionCol=\"prediction\",metricName='accuracy')\n",
    "print(\"Accuracy on training Random Forest is \", myEvaluatorTree.evaluate(finalDFForest))\n",
    "print(\"Accuracy on test Random Forest is \", myEvaluatorTree.evaluate(finalTestDFForest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3d3780d-964d-4ceb-9ca5-50cb5736196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3b242e8-dc53-4d3b-a705-c72eefced670",
   "metadata": {},
   "outputs": [],
   "source": [
    "outRDDForest=finalTestDFForest.select(\"prediction\",\"ClassIndex\").rdd.map(lambda x: (float(x[0]),float(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29384eb7-251b-4366-b9f0-e444c7961d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricsForest=MulticlassMetrics(outRDDForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ff1641b-c201-4181-981a-ac286808d461",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 90:======================================>                   (2 + 1) / 3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0.0 - Precision: 0.6619354838709678, Recall: 0.6185691318327974, F1-Score: 0.6395179721587367\n",
      "Class 1.0 - Precision: 0.789272030651341, Recall: 0.5156445556946183, F1-Score: 0.6237698713096139\n",
      "Class 2.0 - Precision: 0.5784810126582278, Recall: 0.5477427087495006, F1-Score: 0.5626923866201519\n",
      "Class 3.0 - Precision: 0.8220164609053497, Recall: 0.6420249096022499, F1-Score: 0.7209564628919468\n",
      "Class 4.0 - Precision: 0.8089539007092199, Recall: 0.7291250499400719, F1-Score: 0.766967850388737\n",
      "Class 5.0 - Precision: 0.6526717557251909, Recall: 0.7624645318200243, F1-Score: 0.7033090297251823\n",
      "Class 6.0 - Precision: 0.5539380365808138, Recall: 0.5734157650695518, F1-Score: 0.5635086386937537\n",
      "Class 7.0 - Precision: 0.4284876905041032, Recall: 0.8674841772151899, F1-Score: 0.5736332722992414\n",
      "Class 8.0 - Precision: 0.6095238095238096, Recall: 0.38538739462063426, F1-Score: 0.47220855878012785\n",
      "Class 9.0 - Precision: 0.6937056737588653, Recall: 0.621771950735002, F1-Score: 0.6557720511208884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "labels = finalTestDF.select(\"ClassIndex\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "for label in sorted(labels):\n",
    "    print(f\"Class {label} - Precision: {metricsForest.precision(label)}, Recall: {metricsForest.recall(label)}, F1-Score: {metricsForest.fMeasure(label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57ac2bc9-d4b1-4e59-8729-9426c193681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.5.1 Comment your results: which classes are easier to classify? Which get confused themost?\n",
    "#based on F1-score which is balance between percision and recall class 4 has the highest value in both  decision tree\n",
    "#and random forest which means easier to predict they're easier\n",
    "#class 8 has the least F1=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac89a8c-0fcb-4328-9c95-b14fd72d6508",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.5.2 Which classifier performs better? Why do you think it is the case?\n",
    "#the overall accuracy in decision tree is 55% and overall accuracy of random forest is 63% ,random forest performs better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22d9e7b7-a47f-451d-9788-f5aea8b0a0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "outRDDTree=finalTestDF.select(\"prediction\",\"ClassIndex\").rdd.map(lambda x: (float(x[0]),float(x[1])))\n",
    "metricsTree=MulticlassMetrics(outRDDTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d1890f3-8f43-4782-956a-ee008d0bb374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 98:==============================================>           (4 + 1) / 5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0.0 - Precision: 0.48909860071591277, Recall: 0.6043425814234017, F1-Score: 0.5406474820143885\n",
      "Class 1.0 - Precision: 0.73006993006993, Recall: 0.3996937212863706, F1-Score: 0.5165759524987631\n",
      "Class 2.0 - Precision: 0.5596059113300492, Recall: 0.45043616177636797, F1-Score: 0.4991212653778558\n",
      "Class 3.0 - Precision: 0.8428725701943844, Recall: 0.6083398285268901, F1-Score: 0.7066545948392937\n",
      "Class 4.0 - Precision: 0.6887389287220582, Recall: 0.6659869494290375, F1-Score: 0.6771718847190547\n",
      "Class 5.0 - Precision: 0.6893617021276596, Recall: 0.6623058053965658, F1-Score: 0.6755629691409508\n",
      "Class 6.0 - Precision: 0.4521415270018622, Recall: 0.4718227749708511, F1-Score: 0.46177253708634464\n",
      "Class 7.0 - Precision: 0.4313384113166485, Recall: 0.7871326449563145, F1-Score: 0.5572894699845353\n",
      "Class 8.0 - Precision: 0.4924406047516199, Recall: 0.2695035460992908, F1-Score: 0.3483575248281131\n",
      "Class 9.0 - Precision: 0.440793368857312, Recall: 0.6104961049610496, F1-Score: 0.5119477393845625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "labels = finalTestDF.select(\"ClassIndex\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "for label in sorted(labels):\n",
    "    print(f\"Class {label} - Precision: {metricsTree.precision(label)}, Recall: {metricsTree.recall(label)}, F1-Score: {metricsTree.fMeasure(label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "886e8885-c26e-463f-9781-2e1a7f73491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c3134d2-8245-45e6-bcab-1a1767a9ae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3c3672f-8b01-49e4-891b-6bfc3dee5beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb25bba5-eced-431b-a316-d4354a54641c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "paramGrid_dt = ParamGridBuilder().addGrid(dt.maxDepth, [10, 15, 20]).addGrid(dt.impurity, [\"Gini\", \"Entropy\"]).build()\n",
    "myEvaluator_dt =MulticlassClassificationEvaluator(labelCol=\"ClassIndex\",predictionCol=\"prediction\",metricName=\"accuracy\")\n",
    "cvDecisionTree=CrossValidator(estimator=dt,evaluator=myEvaluator_dt,estimatorParamMaps =paramGrid_dt, numFolds=3)\n",
    "DecisionTreeModel = cvDecisionTree.fit(transformedDF)\n",
    "DecisionTreeFinalDf = DecisionTreeModel.transform(transformedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b28abdc-3578-4c66-b586-c986bb3abbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='DecisionTreeClassifier_a581bfed18fb', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       " Param(parent='DecisionTreeClassifier_a581bfed18fb', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'Gini'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTreeModel.getEstimatorParamMaps()[numpy.argmax(DecisionTreeModel.avgMetrics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57382866-d5e2-4fa1-98b9-29cafca130d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "DtNew = DecisionTreeClassifier(labelCol=\"ClassIndex\", featuresCol=\"features\",maxDepth = 20, impurity = \"Gini\")\n",
    "ModelDtNew = DtNew.fit(trainValidation)\n",
    "FinaldfDtNew = ModelDtNew.transform(trainValidation)\n",
    "DtNewTest = ModelDtNew.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1312b3e9-3c91-4659-ac45-56de5dd16457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on new training Decision Tree is  0.7911441378942313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 878:======================================>                  (4 + 2) / 6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on new test Decision Tree is  0.6913033061811212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "myEvaluatorTreNew = MulticlassClassificationEvaluator(labelCol=\"ClassIndex\",predictionCol=\"prediction\",metricName='accuracy')\n",
    "print(\"Accuracy on new training Decision Tree is \", myEvaluatorTree.evaluate(FinaldfDtNew))\n",
    "print(\"Accuracy on new test Decision Tree is \", myEvaluatorTree.evaluate(DtNewTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42fcf82f-e10d-454a-8913-5e55fc8bb973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "paramGridRf = ParamGridBuilder().addGrid(rf.maxDepth, [20,25]).addGrid(rf.numTrees, [20,25]).build()\n",
    "myEvaluatorRf = MulticlassClassificationEvaluator(labelCol=\"ClassIndex\",predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "cvForest=CrossValidator(estimator=rf,evaluator=myEvaluatorRf,estimatorParamMaps =paramGridRf, numFolds=3)\n",
    "cvRfModel=cvForest.fit(transformedDF)\n",
    "finalDFRf=cvRfModel.transform(transformedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61cc382d-a1e0-4b42-8aea-f4ea2b8061de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='RandomForestClassifier_d0daa5384d57', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       " Param(parent='RandomForestClassifier_d0daa5384d57', name='numTrees', doc='Number of trees to train (>= 1).'): 25}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvRfModel.getEstimatorParamMaps()[numpy.argmax(cvRfModel.avgMetrics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68713f8a-f543-46d9-9cab-97dd540fcac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "RfNew = RandomForestClassifier(labelCol=\"ClassIndex\",featuresCol=\"features\",numTrees=25,maxDepth = 20)\n",
    "ModelRfNew = RfNew.fit(trainValidation)\n",
    "FinaldfRfNew = ModelRfNew.transform(trainValidation)\n",
    "RfNewTest = ModelRfNew.transform(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da8a72bd-a67c-4359-b92f-640f33cad934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on new training Random Forest is  0.7669559669852072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1624:============================>                           (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on new test Random Forest is  0.764185614474375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "myEvaluatorForestNew = MulticlassClassificationEvaluator(labelCol=\"ClassIndex\",predictionCol=\"prediction\",metricName='accuracy')\n",
    "print(\"Accuracy on new training Random Forest is \", myEvaluatorTree.evaluate(FinaldfRfNew))\n",
    "print(\"Accuracy on new test Random Forest is \", myEvaluatorTree.evaluate(RfNewTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cded1858-9448-436f-9cf4-76076ba4b488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.6.1 Report the accuracy results for all the parameters you tried. What can youconclude?\n",
    "#Accuracy on training Decision Tree first was  0.55 then reached to 0.79 and for the test it increased from\n",
    "#0.54 to 0.76\n",
    "#Accuracy on training Random Forest first was  0.63 and changed to 0.69 which isn't a significant change.and\n",
    "#for the test it was same as before crossvalidation (0.76)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Yarn)",
   "language": "python",
   "name": "pyspark_yarn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
